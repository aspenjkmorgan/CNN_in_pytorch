{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aspenjkmorgan/CNN_in_pytorch/blob/main/CSCI491_DL_Fall2024_Assignment4_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4 - Convolutional Neural Networks for Computer Vision (v2)"
      ],
      "metadata": {
        "id": "04drDbxf7OaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Aspen Morgan*\n",
        "\n",
        "Note: this assignment falls under collaboration Mode 2: Individual Assignment â€“ Collaboration Permitted. Please refer to the syllabus for additional information.\n",
        "\n",
        "General instructions for software assignments can be found on Moodle."
      ],
      "metadata": {
        "id": "iaV4CZH67Z1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction.**  In this exercise you will utilize convolutional neural networks to solve problems in computer vision, such as image classification, object detection, and segmentation.  \n",
        "\n",
        "**Instructions.** As usual, please submit your code and its output as a pdf file, generated from a Jupyter notebook.  I recommend you complete this assignment in Google CoLab [(link)](https://colab.research.google.com/), but it is also certainly possible to complete it in a local IDE if you first install pytorch (instructions not included here).  The assignment will be divided into \"Problems\", which will be indicated below along with the number of points awarded for completion.  We will begin the assignment by importing important libraries."
      ],
      "metadata": {
        "id": "bwSTtOHG6rEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PROBLEM 1 (40 Total Points)**\n",
        "\n",
        "**Part (a) (10 points)**\n",
        "You will begin this problem by setting up a baseline neural network model, and helper functions, that you developed in the last assignment.  Therefore this first part will mostly involve running code that I provide to you here, or utilizing code that you developed in the previous assignment.  Start by importing the software libraries below."
      ],
      "metadata": {
        "id": "sG_C0K7ye946"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You will need the following libraries to complete the assignment\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "osxUdcBK6m41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now load the MNIST Data**, along with built-in PyTorch data loaders. Run the following code to load the MNIST data."
      ],
      "metadata": {
        "id": "8cCi59hj6itA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the details for the \"transform\" variable\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.05), (0.05))])\n",
        "\n",
        "# We will use a relatively large batch size of 128 here to\n",
        "#  accelerate the training process\n",
        "batch_size = 128\n",
        "\n",
        "# Download the MNIST dataset and data loaders\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Label the classes\n",
        "classes = ('zero', 'one', 'two', 'three',\n",
        "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
      ],
      "metadata": {
        "id": "I_LgnpFEI54u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct a Baseline Model**.  Our baseline model will be a fully-connected neural network with 8 total layers of parameters.  Aside from the output layer, each layer has 50 hidden units, with ReLU activations.  We will call this network *NetFC*.  Note that this is simply the first model that you were asked to create in the previous assignment, however I have provided the code for you below."
      ],
      "metadata": {
        "id": "7UvA1OKe68ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetFc(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.fc1 = nn.Linear(28*28, 50)\n",
        "      self.fc2 = nn.Linear(50, 50)\n",
        "      self.fc3 = nn.Linear(50, 50)\n",
        "      self.fc4 = nn.Linear(50, 50)\n",
        "      self.fc5 = nn.Linear(50, 50)\n",
        "      self.fc6 = nn.Linear(50, 50)\n",
        "      self.fc7 = nn.Linear(50, 50)\n",
        "      self.fc8 = nn.Linear(50, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = torch.flatten(x, 1)\n",
        "      x1 = F.relu(self.fc1(x))\n",
        "      x2 = F.relu(self.fc2(x1))\n",
        "      x3 = F.relu(self.fc3(x2))\n",
        "      x4 = F.relu(self.fc4(x3))\n",
        "      x5 = F.relu(self.fc5(x4))\n",
        "      x6 = F.relu(self.fc6(x5))\n",
        "      x7 = F.relu(self.fc7(x6))\n",
        "\n",
        "      output = self.fc8(x5)\n",
        "\n",
        "      # Return the output of the network\n",
        "      return output"
      ],
      "metadata": {
        "id": "N7vSzXfR1rgg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Helper Functions** In the last assignment you were required to create two functions: *trainMyModel* and *testMyModel*.  You will need to re-use these functions again here and you can paste them here and run them.  To keep the notebook a little cleaner, I import these two functions from another python file called *dl_assignment4_helper_functions*, below.  I use the prefix *hlp* to call these functions. It is up to you whether you paste these functions into the notebook, or import them.  However, note that the code skeletons below assume that they are imported with the *hlp* prefix, and you will have to remove/modify the prefix if you don't import them in a similar fashion."
      ],
      "metadata": {
        "id": "MNCR_SJO4mGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainMyModel(net, lr, trainloader, n_epochs=2, useGPU=False):\n",
        "  optimizer = optim.Adam(net.parameters(), lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Attempt to put your neural network onto the GPU\n",
        "  if useGPU == True:\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "\n",
        "  for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          # inputs is one batch of 128 images, each [1, 28, 28]\n",
        "          if  useGPU == True:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          else:\n",
        "            inputs, labels = data\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Don't forget, your function must print out the training loss on each\n",
        "          # 100th mini-batch\n",
        "          running_loss += loss.item()\n",
        "          if i % 100 == 99:    # print every 100 mini-batches\n",
        "              print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "              running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')\n",
        "  return net\n",
        "\n",
        "def testMyModel(trainedNet, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = trainedNet(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = round((100 * correct / total), 2)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "WXfEF1p22SfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Test the Baseline Model** Now Run your *NetFC* model using a learning rate of 0.01 for 2 epochs.  These values are chosen because they work relatively well.  This model should usually achieve around 94% accuracy, and this will serve as our baseline."
      ],
      "metadata": {
        "id": "2IDnDlo9pF1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model.\n",
        "net = NetFc();\n",
        "lr = 0.01;\n",
        "n_epochs = 2;\n",
        "trainedNet = trainMyModel(net, lr, trainloader, n_epochs);"
      ],
      "metadata": {
        "id": "7_1Y-ZBapyno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dd4d80-db68-4e59-ab42-6b4fd8d19cc2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.680\n",
            "[1,   200] loss: 0.313\n",
            "[1,   300] loss: 0.281\n",
            "[1,   400] loss: 0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,   100] loss: 0.214\n",
            "[2,   200] loss: 0.206\n",
            "[2,   300] loss: 0.200\n",
            "[2,   400] loss: 0.213\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "accuracy = testMyModel(trainedNet,testloader)\n",
        "print(f'The accuracy was {accuracy} percent');"
      ],
      "metadata": {
        "id": "X1Tt5C2eotyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda1887b-b852-4640-f1c6-00655ce9a800"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy was 94.62 percent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part (b) (20 points)** Now we will see the advantages of convolutional structures in a deep neural network.  Below, fill in the template to create convolutional neural network, called 'NetCnn' that has the following structure:\n",
        "\n",
        "layer1: 8 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer2: 16 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer3: 2x2 max pooling, with stride of 2. No zero-padding.\n",
        "\n",
        "layer4: 32 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer5: 64 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer6: 2x2 max pooling, with stride of 2. No zero-padding.\n",
        "\n",
        "layer7: a fully connected layer of 50 neurons.\n",
        "\n",
        "Layer8: a fully connected layer of 10 neurons."
      ],
      "metadata": {
        "id": "aOwGih9UWpDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional model - adding in convolutional layers\n",
        "\n",
        "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
        "#   dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "\n",
        "# torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
        "\n",
        "class NetCnn(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 8, (3, 3), padding=1) # out: 8 channel of 28x28\n",
        "      self.conv2 = nn.Conv2d(8, 16, (3, 3), padding=1) # out: 16 channels of 28x28\n",
        "      self.pool1 = nn.MaxPool2d((2, 2), stride=2) # out: 16 channels of 14x14\n",
        "      self.conv3 = nn.Conv2d(16, 32, (3, 3), padding=1) # out: 32 channels of 14x14\n",
        "      self.conv4 = nn.Conv2d(32, 64, (3, 3), padding=1) # out: 64 channels of 14x14\n",
        "      self.pool2 = nn.MaxPool2d((2, 2), stride=2) # out: 64 channels of 7x7\n",
        "      self.fc1 = nn.Linear(64*7*7, 50) # out: 1 channel flattened with 50 nodes\n",
        "      self.fc2 = nn.Linear(50, 10) # out: 10 nodes corresponding to the 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = F.relu(self.conv1(x))\n",
        "      x2 = F.relu(self.conv2(x1))\n",
        "      x3 = F.relu(self.pool1(x2))\n",
        "      x4 = F.relu(self.conv3(x3))\n",
        "      x5 = F.relu(self.conv4(x4))\n",
        "      x6 = F.relu(self.pool2(x5))\n",
        "      xbuf = torch.flatten(x6, 1) # flatten before passing into fc layer\n",
        "      x7 = F.relu(self.fc1(xbuf))\n",
        "      output = self.fc2(x7)\n",
        "\n",
        "      # Return the output of the network\n",
        "      return output"
      ],
      "metadata": {
        "id": "_utdBDaOW0VN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train the model for 2 epochs using your *trainMyModel* function, which should report the loss every 100 iterations, as was requested in the last assignment.  Then, using *testMyModel* function, evaluate the accuracy of your trained model on the test set. If done correctly, you should obtain around 97% accuracy on the testing set, a relatively significant improvement over *NetFc* if you consider how much error remains.  Note that you may need to tune the learning rate a little bit to achieve this level of accuracy.  \n",
        "\n",
        "Note that we could add skip connections to 'NetCnn' as well, which would further improve its performance, but this is a little tricky and it will not be part of this assignment.  "
      ],
      "metadata": {
        "id": "c6z-CbzUyjOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model.\n",
        "net = NetCnn()\n",
        "lr = 0.01\n",
        "n_epochs = 2;\n",
        "\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs)"
      ],
      "metadata": {
        "id": "e9syyinWW4cV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172c8950-4c50-45f8-cb73-dfdf864d5571"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.648\n",
            "[1,   200] loss: 0.118\n",
            "[1,   300] loss: 0.086\n",
            "[1,   400] loss: 0.085\n",
            "[2,   100] loss: 0.075\n",
            "[2,   200] loss: 0.070\n",
            "[2,   300] loss: 0.073\n",
            "[2,   400] loss: 0.065\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "acc = testMyModel(trainedNet,testloader)\n",
        "print(f'The accuracy was {acc} percent');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAP9wpf9m8Vl",
        "outputId": "3a181cac-df4c-4c57-e6ac-28392d152737"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy was 97.92 percent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part (c) (10 points)**  Compute the number of parameters in the NetFC model and the NetCnn model, respectively, as described in UDL.  Please show your work, and then report your final answer in scientific notation $x \\times 10^y$ where you need to fill in $x$ and $y$.  You need only report $x$ reported to one decimal place, and $y$ should be an integer.  You will be primarily graded on a correct order of magnitude, $y$."
      ],
      "metadata": {
        "id": "UL6PM6bvyn9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NetFC Model**:\n",
        "For a fully connected model, the parameters (weights + bias terms) of each layer will be (in_nodes + bias_node)x(out_nodes).\n",
        "\n",
        "Therefore:\n",
        "$((28*28 + 1)*50 + 7((50 + 1)*50) + ((50 + 1)*10))$ = $5.8 x 10^4$\n"
      ],
      "metadata": {
        "id": "pzRZ55kkRCsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NetCnn Model**:\n",
        "In a convolutional layer, the kernel_size * num_of_filters * num_input_layers + num_of_filters = weights for that layer. Note, the number of filters = the number of output layers. There are no weights in a max pooling layer since it does not need to be trained, it simply chooses the largest value in the pool each time. And the equation for a fully connected layer is above.\n",
        "\n",
        "Therefore: $(1*8*3*3 + 8) + (8*16*3*3 + 16) + (16*32*3*3 + 32) + (32*64*3*3 + 64) + ((64*7*7 + 1) * 50) + ((50 + 1)*10)$ = $1.8x10^5$"
      ],
      "metadata": {
        "id": "w-uYNyWpdJAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part (d) (10 POINTS)**  In this last subproblem, you will add batch normalization layers to your network.  Batch normalization, and its variants (e.g., \"layer norm\") are another structure that is now widely-used in modern deep neural networks.  In this problem you will design a neural network called *NetCnnBn* with the exact same structure as 'NetCnn' except you will add two batch normalization layers in the following locations: (i) after the 2nd convolutional layer, and (ii) after the 1st fully connected layer.  \n",
        "\n",
        "Train your NetCnnBn for 2 epochs using your *trainMyModel* function, and then report its accuracy on the test set using the *testMyModel* function.  If done properly, you should be now be able to achieve approximately 99% accuracy on the testing dataset after two epochs of training.  NOte that you may need to adjust the learning rate again.  Despite this significant performance improvement, note that batch normalization contributes a very small number of parameters.  In our case, for example, it adds $<200$ parameters."
      ],
      "metadata": {
        "id": "hlZ7JHZ2WvqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional model - adding in batch norm\n",
        "class NetCnnBn(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 8, (3, 3), padding=1) # out: 8 channel of 28x28\n",
        "      self.conv2 = nn.Conv2d(8, 16, (3, 3), padding=1) # out: 16 channels of 28x28\n",
        "      self.batch1 = nn.BatchNorm2d(16) # 2d here\n",
        "      self.pool1 = nn.MaxPool2d((2, 2), stride=2) # out: 16 channels of 14x14\n",
        "      self.conv3 = nn.Conv2d(16, 32, (3, 3), padding=1) # out: 32 channels of 14x14\n",
        "      self.conv4 = nn.Conv2d(32, 64, (3, 3), padding=1) # out: 64 channels of 14x14\n",
        "      self.pool2 = nn.MaxPool2d((2, 2), stride=2) # out: 64 channels of 7x7\n",
        "      self.fc1 = nn.Linear(64*7*7, 50) # out: 1 channel flattened with 50 nodes\n",
        "      self.batch2 = nn.BatchNorm1d(50) # 1d now that we've flattended\n",
        "      self.fc2 = nn.Linear(50, 10) # out: 10 nodes corresponding to the 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = F.relu(self.conv1(x))\n",
        "      x2 = F.relu(self.batch1(self.conv2(x1))) # 1st batch norm\n",
        "      x3 = F.relu(self.pool1(x2))\n",
        "      x4 = F.relu(self.conv3(x3))\n",
        "      x5 = F.relu(self.conv4(x4))\n",
        "      x6 = F.relu(self.pool2(x5))\n",
        "      xbuf = torch.flatten(x6, 1)\n",
        "      x7 = F.relu(self.batch2(self.fc1(xbuf))) # 2nd batch norm\n",
        "      output = self.fc2(x7)\n",
        "\n",
        "      # Return the output of the network\n",
        "      return output"
      ],
      "metadata": {
        "id": "Q2UECtlqXIa0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model.\n",
        "net = NetCnnBn();\n",
        "lr = 0.005;\n",
        "n_epochs = 2;\n",
        "\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs);"
      ],
      "metadata": {
        "id": "8qRKLcO0XFZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258fa964-37c0-46ca-b632-a27fcfb0f5f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.295\n",
            "[1,   200] loss: 0.066\n",
            "[1,   300] loss: 0.054\n",
            "[1,   400] loss: 0.053\n",
            "[2,   100] loss: 0.036\n",
            "[2,   200] loss: 0.032\n",
            "[2,   300] loss: 0.036\n",
            "[2,   400] loss: 0.035\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "acc = testMyModel(trainedNet,testloader)\n",
        "print(f'The accuracy was {acc} percent');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgR-jf9wnj3f",
        "outputId": "518de47a-8ffc-4689-8d30-3a3f765aff7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy was 99.26 percent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PROBLEM 2 (20 Total Points)**"
      ],
      "metadata": {
        "id": "uiJygNt6wTO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem you will investigate transfer learning.  Load in a resnet18 model, and initialize its training with weights that were pre-trained on the ImageNet dataset.  Call this model *pretrainedResNet* As a hint, you cannot simply apply a pre-trained resnet18 to this problem; you will need to make two changes to the model structure for it to work properly.  \n",
        "\n",
        "Once you have made the proper modifications (fill in code below), train and test your model on the MNIST data, as you have done with previous models.  If done properly, you should only require a few lines of code, and you should usually obtain around 97% accuracy with 1 epoch of training and the learning rate provided below (lr = 0.0001).  You only need to show your results with these settings. Unfortunately the MNIST dataset is not ideal for demonstrating the tremendous benefits of transfer learning, but this exercise will help familiarize you with the process of adapting pre-trained models to a custom task, which is important in practice.   \n",
        "\n",
        "For this problem I highly recommend that you use a GPU because training willbe  relatively slowly without it (e.g., a couple minutes for 1 epoch, depending upon your hardware).  With a GPU the training should generally run very quickly, finishing in under 30 seconds or less.  Note that you can procure a free GPU to use on Google Colab, however, you are given a limited GPU compute per day unless you pay. Consequently I strongly recommend that you debug on a CPU before deploying onto the GPU.  "
      ],
      "metadata": {
        "id": "f-aul15FwWtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please load a pre-trained resnet-18 model and make the necessary changes so that it will work on the MNIST problem\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "preTrainedResNet = resnet18(weights=ResNet18_Weights)\n",
        "preTrainedResNet"
      ],
      "metadata": {
        "id": "7LSH38QUwaXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b52ea9c-79bb-42cc-ec64-69ee7667bc9c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two changes:\n",
        "1. We want 10 output variables (classes) rather than 1000\n",
        "2. We have B/W images (1 channel) vs 3 input channels to first layer"
      ],
      "metadata": {
        "id": "tt10N6IXx_H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# update first layer (conv1)\n",
        "preTrainedResNet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "# update last layer\n",
        "preTrainedResNet.fc = nn.Linear(512, 10)"
      ],
      "metadata": {
        "id": "m_KBShmHF18X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preTrainedResNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_POu_CK-x7-h",
        "outputId": "1a7dce6d-8a7a-4f7a-97ef-0d5c3657930a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test your model\n",
        "lr = 0.0001;\n",
        "n_epochs = 1;\n",
        "trainedNet = trainMyModel(preTrainedResNet,lr,trainloader,n_epochs, useGPU=True);"
      ],
      "metadata": {
        "id": "ClZUrjOjwdVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f22e9f-ca13-4d7d-dfa4-1da295c770d1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.834\n",
            "[1,   200] loss: 0.219\n",
            "[1,   300] loss: 0.147\n",
            "[1,   400] loss: 0.117\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = testMyModel(trainedNet,testloader)\n",
        "print(f'The accuracy was {acc} percent');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxXDcoj_vwMf",
        "outputId": "ac30c694-dc49-4811-fe03-bfb6848efb18"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy was 97.07 percent\n"
          ]
        }
      ]
    }
  ]
}